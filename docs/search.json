[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Hi y’, welcome little collection workflows, code snippets, ideas proteomics data analysis. Written , ,1 hopefully useful well!nth attempt producing something coherent useful longer period time.2 ’ll see goes :)","code":""},{"path":"index.html","id":"structure","chapter":"Preface","heading":"Structure","text":"","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"first version, spent plenty time thanking people probably less time actually completing started. keep short, possible thanks incredible open stimulating environment Savitski lab members. Thanks guys!","code":""},{"path":"navigation.html","id":"navigation","chapter":"Navigation","heading":"Navigation","text":"previous page describes collection things, motivated workshops past, ’ll contain introductory content well.3If …new R like short refresher, head R Basics4are new R like short refresher, head R Basics4want analyze first proteomics dataset, start withwant analyze first proteomics dataset, start withfancy functional insights biological system,fancy functional insights biological system,look oddly specific solution forlook oddly specific solution forfeel need look raw mass spec data, please enjoy Raw MS Datafeel need look raw mass spec data, please enjoy Raw MS Datawanna browse random pieces code ideas, go5wanna browse random pieces code ideas, go5like style book, copy Github repository modify , read herelike style book, copy Github repository modify , read hereare still satisfied, use search function top left corner. Maybe lucky!still satisfied, use search function top left corner. Maybe lucky!","code":""},{"path":"overview.html","id":"overview","chapter":"2 Overview","heading":"2 Overview","text":"","code":""},{"path":"data-handling.html","id":"data-handling","chapter":"3 Data Handling","heading":"3 Data Handling","text":"","code":""},{"path":"data-handling.html","id":"import","chapter":"3 Data Handling","heading":"3.1 Import","text":"\nabc","code":"\nDatasets[[\"dataset_SILAC\"]] <-\n  import2new_dataset_diann_precursor_SILAC(\n    raw.data = Info$Imports$dataset_SILAC,\n    variables.data = c(\"Protein.Group\",\n                       \"Protein.Ids\",\n                       \"Protein.Names\",\n                       \"Genes\",\n                       \"First.Protein.Description\",\n                       \"Proteotypic\",\n                       \"Stripped.Sequence\",\n                       \"Modified.Sequence\",\n                       \"Precursor.Mz\",\n                       \"Precursor.Charge\",\n                       \"Precursor.Id\"),\n    observations = c(\"name01\" = \"sample_name01\",\n                     \"name02\" = \"sample_name02\",\n                     \"name03\" = \"sample_name03\",\n                     \"name04\" = \"sample_name04\",\n                     \"name05\" = \"sample_name05\",\n                     \"name06\" = \"sample_name06\",\n                     \"name07\" = \"sample_name07\",\n                     \"name08\" = \"sample_name08\"),\n    data.frames = c(\"Precursor.Quantity\", \n                    \"Precursor.Normalised\", \n                    \"Ms1.Area\", \n                    \"Ms1.Normalised\"))\n# pull all sample names \nInfo$Imports$sta10_6mz$Run %>% \n  # keep individual names in desired order \n  unique() %>% \n  sort(decreasing = T) %>% \n  # add names to vector \n  setNames(., strsplit_keep_last(., \"_\")) %>% \n  # print vector to copy to script \n  .cat_character_named()\nInfo$Imports$sta10_6mz$Run %>% \n  unique() %>% \n  sort(decreasing = T) %>% \n  setNames(., strsplit_keep_last(., \"_\")) %>% \n  .cat_character_named()"},{"path":"data-handling.html","id":"preprocessing","chapter":"3 Data Handling","heading":"3.2 Preprocessing","text":"","code":""},{"path":"introduction.html","id":"introduction","chapter":"5 Introduction","heading":"5 Introduction","text":"","code":""},{"path":"tpp.html","id":"tpp","chapter":"6 TPP","heading":"6 TPP","text":"","code":""},{"path":"spp.html","id":"spp","chapter":"7 SPP","heading":"7 SPP","text":"","code":""},{"path":"pelsa.html","id":"pelsa","chapter":"8 PELSA","heading":"8 PELSA","text":"","code":""},{"path":"pelsa.html","id":"the-ht.pelsa-package","chapter":"8 PELSA","heading":"8.1 The HT.PELSA package","text":"","code":""},{"path":"pelsa.html","id":"qc-for-dose-response-results","chapter":"8 PELSA","heading":"8.2 QC for Dose-Response Results","text":"Let’s load libraries first.PELSA output HT.PELSA package immediately show replicates peptide identified hit. information can retrieved data_EC50$data_replicates table.Next, can look distribution peptide hits across different replicates.investigate, whether identification biased replicates towards different numbers hits, can check many replicates hit quantified curve fitted.Looking good!Considering now peptides curves fitted, can visualize first upset plot fitted peptide curves, independent identified hit end.Finally, can see number fitted peptide curves equal among replicates peptides., can count number peptides quantified per replicate concentration, represent heatmap.Don’t get fooled automatic color scale!Sometimes, may bias within EC50 values. can also visualize .can separated stabilized destabilized peptides well.\nMaybe helps plot difference replicate mean pEC50 values. can done like .can scaled dividing difference mean value .\nFinally, pEC50 values can compared among replicates via correlation matrix pEC50 values.","code":"\nlibrary(tidyverse)\nlibrary(pOmics3)\nlibrary(UpSetR)\nlibrary(ComplexHeatmap)\n\"Z:/savitski/02_projects/16_PELSAopti/HT-PELSA_publication/rawdata/ATP_DD_report.pr_matrix.tsv\"\n#> [1] \"Z:/savitski/02_projects/16_PELSAopti/HT-PELSA_publication/rawdata/ATP_DD_report.pr_matrix.tsv\"\n# Extract replicate hits per peptide \ndata_hit_replicates <- data_EC50$data_replicates %>% \n  filter(regulation %in% c(\"stabilized\", \"destabilized\") & \n           regulation_replicate %in% c(\"stabilized\", \"destabilized\")) %>% \n  arrange(Peptides, Replicate) %>% \n  summarise(Replicate.Hits = \n              paste(Replicate[regulation %in% c(\"stabilized\", \"destabilized\")], \n                                   collapse = \"/\"), \n            .by = \"Peptides\")\n# Peptide hit distribution over replicates \ndata_EC50$data_replicates %>% \n  # Identify hits \n  filter(regulation %in% c(\"stabilized\", \"destabilized\")) %>% \n  # Remove unchanged peptide replicates \n  filter(regulation_replicate %in% c(\"stabilized\", \"destabilized\")) %>% \n  arrange(Peptides, Replicate) %>% \n  pivot_wider(id_cols = \"Peptides\", \n              names_from = \"Replicate\", \n              values_from = \"regulation\") %>% \n  mutate(across(2:5, \\(x) as.numeric(!is.na(x)))) %>% \n  pOmics3::t2df() %>% \n  UpSetR::upset(order.by = \"freq\", \n                mainbar.y.label = \"# peptide hits\", \n                sets.x.label = \"# peptide hits\")\n# Distribution of fitted curves for hits \ndata_EC50$data_replicates %>% \n  # Identify hits \n  dplyr::filter(regulation %in% c(\"stabilized\", \"destabilized\")) %>% \n  dplyr::arrange(Peptides, Replicate) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n              names_from = \"Replicate\", \n              values_from = \"do.fit\") %>% \n  dplyr::mutate(across(2:5, \\(x) as.numeric(tidyr::replace_na(x, F)))) %>% \n  pOmics3::t2df() %>% \n  UpSetR::upset(order.by = \"freq\", \n                mainbar.y.label = \"# fitted peptides curves (among hits)\", \n                sets.x.label = \"(same as y-axis)\")\n# Hit distribution of all fitted curves \ndata_EC50$data_replicates %>% \n  #filter(regulation %in% c(\"stabilized\", \"destabilized\")) %>% \n  dplyr::filter(regulation_replicate %in% c(\"stabilized\", \"destabilized\")) %>% \n  dplyr::arrange(Peptides, Replicate) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n              names_from = \"Replicate\", \n              values_from = \"regulation\") %>% \n  mutate(across(2:5, \\(x) as.numeric(!is.na(x)))) %>% \n  pOmics3::t2df() %>% \n  UpSetR::upset(order.by = \"freq\", \n                mainbar.y.label = \"# peptide replicate hits\", \n                sets.x.label = \"(same as y-axis)\")\n# Distribution of fitted curves for hits \ndata_EC50$data_replicates %>% \n  #filter(regulation %in% c(\"stabilized\", \"destabilized\")) %>% \n  dplyr::arrange(Peptides, Replicate) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n              names_from = \"Replicate\", \n              values_from = \"do.fit\") %>% \n  dplyr::mutate(across(2:5, \\(x) as.numeric(tidyr::replace_na(x, F)))) %>% \n  pOmics3::t2df() %>% \n  UpSetR::upset(order.by = \"freq\", \n                mainbar.y.label = \"# fitted peptides curves (all peptides)\", \n                sets.x.label = \"(same as y-axis)\")\n# Heatmap of number of quantified peptides \ndata_EC50$data_replicates %>% \n  dplyr::select(Peptides, Replicate, found_in) %>% \n  tidyr::separate_longer_delim(found_in, \"/\") %>% \n  dplyr::count(Replicate, found_in) %>% \n  dplyr::filter(found_in!= \"\") %>% \n  tidyr::pivot_wider(names_from = \"found_in\", values_from = n) %>% \n  t2m() %>% \n  #t() %>% \n  ComplexHeatmap::Heatmap(cluster_columns = F, name = \"# quantified peptides\")\n# Heatmap of pEC50 values for hits \ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean)) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  ComplexHeatmap::Heatmap(name = \"pEC50\", \n                          show_row_names = F)\n# for stabilized hits\ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean) & regulation == \"stabilized\") %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  ComplexHeatmap::Heatmap(name = \"pEC50\", \n                          show_row_names = F)\n# for destabilized hits\ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean) & regulation == \"destabilized\") %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  ComplexHeatmap::Heatmap(name = \"pEC50\", \n                          show_row_names = F)\n# pEC50 - pEC50_mean values\ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean)) %>% \n  dplyr::mutate(pEC50 = pEC50 - pEC50_mean) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  ComplexHeatmap::Heatmap(name = \"pEC50 - pEC50_mean\", \n                          show_row_names = F)\n# Scaled pEC50 - pEC50_mean values\ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean)) %>% \n  dplyr::mutate(pEC50 = (pEC50 - pEC50_mean) / pEC50_mean) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  ComplexHeatmap::Heatmap(name = \"(pEC50 - pEC50_mean) / pEC50_mean\", \n                          show_row_names = F)\n# Correlation matrix of pEC50 values \ndata_EC50$data_replicates %>% \n  dplyr::filter(!is.na(pEC50_mean)) %>% \n  tidyr::pivot_wider(id_cols = \"Peptides\", \n                     names_from = \"Replicate\", \n                     values_from = \"pEC50\") %>% \n  t2m() %>% \n  cor(use = \"pairwise.complete.obs\") %>% \n  ComplexHeatmap::Heatmap(name = \"pEC50\")"},{"path":"overview-1.html","id":"overview-1","chapter":"10 Overview","heading":"10 Overview","text":"","code":""},{"path":"overview-2.html","id":"overview-2","chapter":"12 Overview","heading":"12 Overview","text":"","code":""},{"path":"overview-3.html","id":"overview-3","chapter":"14 Overview","heading":"14 Overview","text":"","code":""},{"path":"interactive-data-analysis.html","id":"interactive-data-analysis","chapter":"15 Interactive Data Analysis","heading":"15 Interactive Data Analysis","text":"","code":""},{"path":"interactive-data-analysis.html","id":"quick-example","chapter":"15 Interactive Data Analysis","heading":"15.1 Quick example","text":"non-app interactive Volcano plot connects original data:interactive plot via ggplot2 plotlyconnection plot table via crosstalk (check )canvas put together bslibDone! One function layout_columns allow us make bit screen-friendly.Oh, like use tool select number points plot, simply change selection argument datatable \"multiple\". fun, Tara :)","code":"\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(crosstalk)\nlibrary(bslib)\nlibrary(DT)\n\n# Our data\ndata <- tibble(x = c(1, 2, 3), \n               y = c(1, 2, 3), \n               gene = c(\"A\", \"B\", \"C\"))\n\n# Plot \ndata %>% \n  ggplot(aes(x = x, y = y, gene = gene)) + \n  geom_point() + \n  theme_classic()\n\n# Shared data object \ndata_plot <- SharedData$new(data = data, \n                            key = ~gene)\n\n# Initial plot \np <- data_plot %>% \n  ggplot(aes(x = x, y = y, gene = gene)) + \n  geom_point() + \n  theme_classic()\n\n# Make plot interactive \nggplotly(p)\n\n# Put all together \npage_fillable(ggplotly(p, ), \n              datatable(data_plot, selection = \"single\"))\n# Add a specific layout \npage_fillable(\n  layout_columns(\n    col_widths = c(6, 6), \n    row_heights = 1, \n    ggplotly(p), \n    datatable(data_plot, selection = \"single\")))"},{"path":"raw-ms-data.html","id":"raw-ms-data","chapter":"17 Raw MS Data","heading":"17 Raw MS Data","text":"","code":""},{"path":"raw-ms-data.html","id":"introduction-1","chapter":"17 Raw MS Data","heading":"17.1 Introduction","text":"Sometimes useful look raw MS data, like chromatography runs, number peaks per spectrum something else like isolation window boundaries DIA MS2 spectra. Much manual evaluation LC-MS data done Thermo Xcalibur OpenMS, however allow script specific task. , can load raw MS data R .","code":""},{"path":"raw-ms-data.html","id":"read-.raw-files","chapter":"17 Raw MS Data","heading":"17.2 Read .raw files","text":"","code":""},{"path":"raw-ms-data.html","id":"extract-meta-data","chapter":"17 Raw MS Data","heading":"17.3 Extract meta data","text":"","code":""},{"path":"raw-ms-data.html","id":"extract-spectral-data","chapter":"17 Raw MS Data","heading":"17.4 Extract spectral data","text":"","code":""},{"path":"r-and-rstudio.html","id":"r-and-rstudio","chapter":"18 R and RStudio","heading":"18 R and RStudio","text":"“R ‘GNU S’, freely available language environment statistical computing graphics provides wide variety statistical graphical techniques: linear nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc.”description R R website.","code":""},{"path":"r-and-rstudio.html","id":"install-the-r-language","chapter":"18 R and RStudio","heading":"18.1 Install the R language","text":"Download recent release R platform https://cloud.r-project.org/. Install like program. important install R RStudio.","code":""},{"path":"r-and-rstudio.html","id":"install-rstudio","chapter":"18 R and RStudio","heading":"18.2 Install RStudio","text":"RStudio integrated development environment (IDE) R. IDEs exist, RStudio software choice far. Like, far. Download desktop version RStudio https://www.rstudio.com/products/rstudio/. program interact R language conduct analyses.","code":""},{"path":"how-does-r-work.html","id":"how-does-r-work","chapter":"19 How does R work?","heading":"19 How does R work?","text":"“understand computations R, two slogans helpful:\nEverything exists object.\nEverything happens function call.” — John Chambers6Ok, cool. now? Well, statement tells us everything R code falls two categories, either object function (likely take object input give back modified object return).","code":""},{"path":"how-does-r-work.html","id":"objects","chapter":"19 How does R work?","heading":"19.1 Objects","text":"Please look Workflow: basics first introduction recapitulation7 coding R.\nimportant takeaway can assign/create object R assignment operator <-. , c ombine function c()8 one frequently used functions R.can simply copy code marking pressing helpful button top right corner code chunk paste R script. just run lines code look produce.c(1, 2, 3) -> numbers works well, please ever .9\ncreated called vector, precisely atomic vector. means elements type. can read Vectors chapter Advanced R waiting time unsure behavior vectors. Examples :unhappy type data changed previous example, simply change c() list().10\ndata types can found Vectors chapter mentioned previously covered throughout project.","code":"\n# Assign the vector to an object called numbers\nnumbers <- c(1, 2, 3)\n# Execute the following line to print it to the console\nnumbers\n# Some objects (not this one) need to be forced to show in the console \nprint(numbers)\nmixed_numbers <- c(0, 1, 2, \"three\")\nmixed_numbers_2 <- c(F, TRUE, 2, 3)\n# You don't actually need to assign them\nc(F, TRUE, 2, \"three\")\nlist(0, 1, 2, \"three\")\nlist(F, TRUE, 2, 3)\nlist(\"these\" = F, \"are\" = TRUE, \"names\" = 2, \"three\")\nlist(\"and\" = F, \n     \"they\" = TRUE, \n     \"work\" = 2, \n     \"notemptyanymore\" = \"for both lists and vectors :)\")"},{"path":"how-does-r-work.html","id":"functions","chapter":"19 How does R work?","heading":"19.2 Functions","text":"Besides basic object R, vector, also covered two functions well. c() list() functions allow us create atomic vector list objects. want understand function, simply write ?c11 R prompt documentation function Help pane bottom right.12The number functions exceeds number object types far, therefore see use functions properly. function 1. name, 2. object 3. can evoked () brakets following name. Let’s try :Nice! bad example. Write function name sum wait list options appear. happen, can press Tab. see list, scroll arrow buttons choose function Tab Enter. cursor brackets function, press Tab . Now, see arguments function. Arguments different inputs function declare precisely input goes within function. bad example special type argument ..., (dot-dot-dot), accepts undefined number arguments, case multiple numbers.better example intersect() function, takes two sets form atomic vectors x y returns intersection.Set Operation functions useful one point sure. Another resource worth mentioning example generalis R-bloggers website.formal description functions, can read Function fundamentals. now let’s see functions come .","code":"\nsum(1, 2, 3)\nintersect(x = c(1, 2, 3), \n          y = c(2, 3, 4))"},{"path":"r-packages.html","id":"r-packages","chapter":"20 R packages","heading":"20 R packages","text":"“R packages collections functions data sets developed community. increase power R improving existing base R functionalities, adding new ones.”13Basically, R packages nothing collections functions bundled together way makes sense. Like different cookbooks contain recipes particular kind food. can installed many different sources explored .","code":""},{"path":"r-packages.html","id":"from-cran","chapter":"20 R packages","heading":"20.1 From CRAN","text":"Comprehensive R Archive Network (CRAN) package repository features 18,000+ R packages. ’s list Available CRAN Packages Name. general purpose packages can found , however due reasons, packages available sources.first example, download tidyverse, collection R packages data science.“tidyverse opinionated collection R packages designed data science. packages share underlying design philosophy, grammar, data structures.”can install packages CRAN install.packages() function like :Note, can also download one package using vector (c()) containing package names:BiocManager well devtools used following download R packages sources.","code":"\ninstall.packages(\"tidyverse\")\ninstall.packages(c(\"BiocManager\", \"devtools\"))"},{"path":"r-packages.html","id":"from-bioconductor","chapter":"20 R packages","heading":"20.2 From Bioconductor","text":"Bioconductor collection R packages bioinformatics purposes. first packages need Bioconductor downloaded install() function BiocManager package:","code":"\nBiocManager::install(c(\"fgsea\",\n                       \"org.Hs.eg.db\",\n                       \"UniProt.ws\"))"},{"path":"r-packages.html","id":"from-github-and-others-sources","chapter":"20 R packages","heading":"20.3 From GitHub and others sources","text":"Another important source R packages GitHub. GitHub just place R packages developed put repositories CRAN Bioconductor, many packages including PELSA package can installed well.example install_github() function devtools package. package required yet.","code":"\ndevtools::install_github(\"nicohuttmann/PELSA\")"},{"path":"the-tidyverse.html","id":"the-tidyverse","chapter":"21 The tidyverse","heading":"21 The tidyverse","text":"may already installed tidyverse previous chapter. collection many R packages made data science. see high level dialect - allows base R“tidyverse opinionated collection R packages designed data science. packages share underlying design philosophy, grammar, data structures.”tidyverse extensively described R Data Science (2e) book14 recommended Learn tidyverse individual packages summarized Posit cheatsheets.","code":""},{"path":"coding-style.html","id":"coding-style","chapter":"22 Coding style","heading":"22 Coding style","text":"Okay, nearly made project. One last chapter. promise.One decision may already guessed, follower tidyverse try use instead base R solutions wherever possible.15 Still, almighty sometimes need solutions. example dividing two data frames require tidyverse functions pivot_longer, inner_join, mutate pivot_wider. elegant base R solution data matrices simply using mathematical operator /.Damn, writing example, found trying show work, somehow work. let explain don’t like example.structure object R can found using class() function. Just try .objects base R example matrices. Let’s check tidyverse example.output divide operation tibble/“tbl_df” object anymore, data.frame. big problem now, can solved quite easily tibble::as_tibble() function:However, recommended change class data way analysis.real tidyverse solution work following. key combine tibbles one allows us divide columns simple dplyr::mutate() operation.seems like tedious example comparison, also bears ’s advantages see later.Btw, ’ve done code-condensed form.need understand immediately, common operations omics data science. understand tidyr::pivot_longer/wider functions within week, ’re years ahead compared journey data science :)","code":"\nm1 <-  matrix(1:9, nrow = 3)\n\nm2 <-  matrix(1:9, nrow = 3) * 2\n\nm2 / m1\n# Making the tibble works slightly different in our exampe \nt1 <- tibble(a = 1:3, b = 4:6, c = 7:9)\n# and multiplying each element by 2 gets done with mutate and across. \n# We will get back to this later\nt2 <- tibble(a = 1:3, b = 4:6, c = 7:9) %>% \n  # \\(x) x * 2 is equivalent to function(x) x * 2\n  mutate(across(everything(), \\(x) x * 2))\n\nt2 / t1\nclass(m1)\n\nclass(m2)\n\nclass(m2 / m1)\nclass(t1)\n\nclass(t2)\n\nclass(t2 / t1)\ntibble::as_tibble(t2 / t1)\n# First we add a row column to the tibbles, this brings them closer to real data \nt1_r <- t1 %>% \n  mutate(row = c(\"1\", \"2\", \"3\"), \n         .before = 1)\n# Do it again \nt2_r <- t2 %>% \n  mutate(row = c(\"1\", \"2\", \"3\"), \n         .before = 1)\n# Now we bring our data from a wide format into a long format \nt1_long <- pivot_longer(t1_r, \n                        cols = c(\"a\", \"b\", \"c\"), \n                        names_to = \"column\", \n                        values_to = \"number\")\n# And again \nt2_long <- pivot_longer(t2_r, \n                        cols = -1, \n                        names_to = \"column\", \n                        values_to = \"number\")\n\n# We start with combining the data frames by matching both tibbles by the \n# columns \"row\" and \"column\" and choosing a suffing for overlapping column names\nfull_join(t1_long, t2_long, by = c(\"row\", \n                                   \"column\"), \n          suffix = c(\"_1\", \"_2\")) %>% \n  # Then we can divide the values of t2 by t1 and save them in a new column \n  mutate(number = number_2 / number_1) %>% \n  # Now we finally pivot back to the wide data format from the beginning\n  pivot_wider(id_cols = \"row\", \n              names_from = \"column\", \n              values_from = \"number\")\n# First we put the tibbles in a list \nlist(\"t1\" = t1, \"t2\" = t2) %>% \n  # map allows us to do the same computation for all objects of the list as \n  # defined by the function \\(x) x...\n  map(\\(x) x %>% \n        mutate(row = c(\"1\", \"2\", \"3\"), \n               .before = 1) %>% \n        pivot_longer(cols = -1, \n                     names_to = \"column\", \n                     values_to = \"number\")) %>% \n  # Once both tibbles are ready to be combined, we can access them via the with \n  # function (we may talk about this again, I find it very helpful sometimes)\n  with(full_join(t1, t2, by = c(\"row\", \n                                \"column\"), \n                 suffix = c(\"_1\", \"_2\"))) %>% \n  # Now we continue as above\n  mutate(number = number_2 / number_1) %>% \n  # And back to a wide format tibble \n  pivot_wider(id_cols = \"row\", \n              names_from = \"column\", \n              values_from = \"number\")"},{"path":"coding-style.html","id":"coding-style-1","chapter":"22 Coding style","heading":"22.1 Coding style","text":"Well, ?! pipe. %>% . ?16We previously learned “Everything happens function call.” order result function ‘exist’, need assign object. Fine. Works. happens need multiple operations object get result?Let’s consider generic example vector contains letters like count represent barplot.first exercise book17. done code, observe happened continue code .code yields barplot represents frequency letter. get result, created two intermediate objects random_letters_table random_letters_table_sorted. can random_letters object, simply overwriting line.saw examples different ways chain outputs different computations arrive barplot. Let’s try use %>% operator simplify process.chain begins object random_letters followed functions subsequent line. output preceding line always used first argument following function.equivalent nested construct:18I hope obvious %>% useful tool, just writing less code also making code legible. Btw, find hidden message barplot? , try stretch ‘Plots’ window press ‘Zoom’ ‘Plots’ panel.making exercise even better example utility %>% :)\nprobably better explanation pipes -depth explanation, please look corresponding chapter R Data Science chapter second edition, R Data Science (2e).Using %>% pipe operator one part Style guide big impact legibility code. visually prefer old version suggest reading one two. beginning coding career, recommendations immediately obvious, remember later .","code":"\nletters_freq <- c(\"A\" = 5, \"B\" = 18, \"C\" = 20, \"D\" = 2,\n                  \"E\" = 24, \"F\" = 13, \"G\" = 1, \"H\" = 25,\n                  \"I\" = 21, \"J\" = 11, \"K\" = 19, \"L\" = 6,\n                  \"M\" = 10, \"N\" = 14, \"O\" = 16, \"P\" = 9,\n                  \"Q\" = 23, \"R\" = 17, \"S\" = 8, \"T\" = 26,\n                  \"U\" = 22, \"V\" = 7, \"W\" = 15, \"X\" = 12,\n                  \"Y\" = 3, \"Z\" = 4)\n\nrandom_letters <- rep(names(letters_freq), letters_freq)\n# Count each element of random_letters \nrandom_letters_table <- table(random_letters)\n# Sort table in decending order \nrandom_letters_table_sorted <- sort(random_letters_table, decreasing = T)\n# Plot the frequency of each letter \nbarplot(random_letters_table_sorted)\n# Count each element of random_letters \nrandom_letters <- table(random_letters)\n# Sort table in descending order \nrandom_letters <- sort(random_letters, decreasing = T)\n# Plot the frequency of each letter \nbarplot(random_letters)\n# We reassign random_letters since we overwrote it in the previous example\nrandom_letters <- rep(names(letters_freq), letters_freq)\n\nrandom_letters %>%  \n  table() %>% \n  sort(decreasing = T) %>% \n  barplot()\nbarplot(sort(table(random_letters), decreasing = T))\nsentence_full <- \"The quick brown fox jumps over the lazy dog\"\n## Unrelated but, wow I just discovered there's a `sentences` object in R\n\n# Generate the frequency of each individual letter\nletters_freq <- sentence_full %>% \n  # Remove spaces\n  str_remove_all(\" \") %>% \n  # Split the string into individual letters \n  str_split(\"\") %>% \n  # Extract vector from list \n  unlist() %>% \n  # Make all letters upper case\n  toupper() %>% \n  # Remove dublicated letters \n  unique() %>% \n  # Make vector with letters as names and numbers from 26 to 1 as content\n  # Do you see how the . marks the position of the argument coming from the previous line?\n  setNames(26:1, .) %>% \n  # Reorder the vector so that the solution is not immediately obvious to you guys \n  # Not this is some weird stuff here, do try this at home\n  `[`(., order(names(.)))\n\n# Test if it works\nrandom_letters <- rep(names(letters_freq), letters_freq)\n\n\n# Now prepare the example for the exercise\n\n# This function copies a vector to the console \n.cat_character_named <- function(...) {\n  \n  n <- paste0(names(...), '\" = \"', ..., '\"')\n  \n  cat(paste0('c(\"', paste(n, collapse = ',\\n\\t\"'), ')'))\n  \n}\n\n.cat_character_named(random_letters)\n\nletters_freq <- c(\"A\" = 5,\n                  \"B\" = 18,\n                  \"C\" = 20,\n                  \"D\" = 2,\n                  \"E\" = 24,\n                  \"F\" = 13,\n                  \"G\" = 1,\n                  \"H\" = 25,\n                  \"I\" = 21,\n                  \"J\" = 11,\n                  \"K\" = 19,\n                  \"L\" = 6,\n                  \"M\" = 10,\n                  \"N\" = 14,\n                  \"O\" = 16,\n                  \"P\" = 9,\n                  \"Q\" = 23,\n                  \"R\" = 17,\n                  \"S\" = 8,\n                  \"T\" = 26,\n                  \"U\" = 22,\n                  \"V\" = 7,\n                  \"W\" = 15,\n                  \"X\" = 12,\n                  \"Y\" = 3,\n                  \"Z\" = 4)"},{"path":"coding-style.html","id":"data-organization-wihtin-r","chapter":"22 Coding style","heading":"22.2 Data organization wihtin R","text":"moving basics actual project, let’s see work R. Working R means packages code use, working R means put code data. Let’s start top level. scripts data live?","code":""},{"path":"coding-style.html","id":"r-projects","chapter":"22 Coding style","heading":"22.2.1 R projects","text":"just work R project, also work one. Please look description R projects now well known book. get closer Group Work Project let’s start creating place data code.Create R project course. suggest make folder called R within Documents folder wherever store research. , start collect different R projects.\ncan create new R project clicking File -> New Project… -> New Directory -> New Project. Now enter name19, browse top folder like press Create Project. want keep current R session open, tick Open new session.\nmay seem convenient folder server lab, gets archived automatically, however, sometimes gives trouble slows analysis. Copying R folder time time seems like practical solution .\nGreat, created first R project. can identify project name window written top right corner.creating first R script, can set folder structure within R project. can done operating system’s file explorer function dir.create. usually begin setting work directory like :like :)","code":"\n# All R and Rmd scripts will be in here \ndir.create(\"Scripts\")\n# All raw data can be stored here \ndir.create(\"Data\")\n# A separate folder for RData objects \ndir.create(\"Data/RData\")\n# All output like figures, tables etc. \ndir.create(\"Output\")"},{"path":"coding-style.html","id":"lists-and-.lists","chapter":"22 Coding style","heading":"22.2.2 Lists and .lists","text":"Now data tidy place live operating system. Nice. data R?Everything R lives Global Environment. can read , free time specific questions.previously touched vectors lists, main difference vectors take one kind element lists can store whatever fancy. ’s want.Imagine need compute following incredibly complicated numbers want store meeting PI later:Omg, see Global Environment top right gets cluttered. PI won’t like . Let’s tidy using list.Click important_numbers top right20 can view content list. equivalent writing View(important_numbers) console R script.Finally, let’s clean mess deleting previously created R objects named , b, c . can rm() function. different ways use .One last trick. notice never saw .c Global Environment. created hidden object . prefix. can find objects(.names = T) remove just .good practice clean environment end analysis chunk end script remove things don’t need anymore. talking gigabytes data instead lousy numbers, try gc() deleting objects.21","code":"\na <- 1 + 1\nb <- 2 - 3\nc <- 2 * Inf\nd <- 1 / 0\ne <- 2^2\nf <- sqrt(2)\ng <- exp(1)\nh <- log10(3)\ni <- log2(42)\nj <- log(pi, base = pi)\nk <- a > b\nl <- a < b\nm <- a == b\nn <- a >= b\no <- a <= b\n# Directly store the first numbers in the list\nimportant_numbers <- list(\n  a = 1 + 1, \n  b = 2 - 3, \n  c = 2 * Inf, \n  # You can also use a string \"d\" to define the name, it's the same\n  \"d\" = 1 / 0)\n\n# Add the remaining numbers\nimportant_numbers[[\"e\"]] <- 2^2\nimportant_numbers[[\"f\"]] <- sqrt(2)\nimportant_numbers[[\"g\"]] <- exp(1)\nimportant_numbers[[\"h\"]] <- log10(3)\nimportant_numbers[[\"i\"]] <- log2(42)\nimportant_numbers[[\"j\"]] <- log(pi, base = pi)\nimportant_numbers[[\"k\"]] <- a > b\nimportant_numbers[[\"l\"]] <- a < b\nimportant_numbers[[\"m\"]] <- a == b\nimportant_numbers[[\"n\"]] <- a >= b\nimportant_numbers[[\"o\"]] <- a <= b\n# Remove one object\nrm(a)\n# Remove multiple object \nrm(b, c)\n# Or \nrm(list = c(\"d\", \"e\"))\n# To remove everything use the object() function\nobjects()\n# and combine the two\nrm(list = objects())\n# Uups, everthing is gone. If you want to keep something add setdiff\na <- 1\nb <- 2\n.c <- 3\n# Remove all but a\nrm(list = setdiff(objects(), \"a\"))"},{"path":"coding-style.html","id":"summary","chapter":"22 Coding style","heading":"22.3 Summary","text":"Thanks making far. intro R Basics ended quite extensive, getting give tools figure problems R . examples useful yet, may come handy later. Basically every piece code used work one point.lot functions get know, especially tidyverse, cover way. Please remember:Question everything understand seems unclear.always one way get goal, redundancy helps us understand things better.Let us know, different better way something, ’re discuss!","code":""},{"path":"version-control-with-github.html","id":"version-control-with-github","chapter":"24 Version control with GitHub","heading":"24 Version control with GitHub","text":"Excuse , moment talk version control?22There lot say GitHub one may use . extensive discussion topic basically everything learn chapter can found Happy Git GitHub useR.chapter introduce basics collaborate people using GitHub, probably reason reading first place.","code":""},{"path":"version-control-with-github.html","id":"headstart-into-git-and-github-with-rstudio","chapter":"24 Version control with GitHub","heading":"24.1 Headstart into Git and GitHub with RStudio","text":"following post provides quick introduction set Git GitHub connect GitHub account RStudio: https://www.bioinformatics.babraham.ac.uk/training/RStudio_GitHub/Initial_setup.html.done, able connect download online GitHub repositories able start collaborating projects immediately.","code":""},{"path":"version-control-with-github.html","id":"basic-github-routine","chapter":"24 Version control with GitHub","heading":"24.2 Basic GitHub routine","text":"Open Git terminal R start lines code.Add files:Commit changes:Push commits:…","code":"git add .git commit -m \"Add important changes\"git push"},{"path":"version-control-with-github.html","id":"common-problems","chapter":"24 Version control with GitHub","heading":"24.3 Common problems","text":"following provide summary common problems encountered using Git. also serves reminder .","code":""},{"path":"version-control-with-github.html","id":"too-large-files","chapter":"24 Version control with GitHub","heading":"24.3.1 Too large files","text":"Original post answer: https://stackoverflow.com//17890278.Download BFG Repo-Cleaner jar file “bfg-x.xx.x.jar” (e.g. “bfg-1.14.0.jar”) https://rtyley.github.io/bfg-repo-cleaner/.Download BFG Repo-Cleaner jar file “bfg-x.xx.x.jar” (e.g. “bfg-1.14.0.jar”) https://rtyley.github.io/bfg-repo-cleaner/.Place file directory R project, .git folder.Place file directory R project, .git folder.Open terminal folder (e.g. via RStudio > Git > Shell…)Open terminal folder (e.g. via RStudio > Git > Shell…)Type terminal:Type terminal:file name “bfg.jar” must match name jar file file size limit can changed (e.g. 50M 50 )encouter error, type:clean dead data.encounter following error Warning : large blobs matching criteria found packfiles - repo need packed?, refer post https://stackoverflow.com/q/61769785 type git gc prior step 4.","code":"java -jar bfg.jar --strip-blobs-bigger-than 100Mgit gc --prune=now --aggressive"},{"path":"version-control-with-github.html","id":"gitignore-does-not-instantly-work","chapter":"24 Version control with GitHub","heading":"24.3.2 .gitignore does not instantly work","text":"Just :","code":"git rm -r --cached .\ngit add .\ngit commit -m \"Drop files from .gitignore\""},{"path":"blog.html","id":"blog","chapter":"26 Blog","heading":"26 Blog","text":"","code":""},{"path":"blog.html","id":"idea","chapter":"26 Blog","heading":"26.1 Idea","text":"","code":""}]
